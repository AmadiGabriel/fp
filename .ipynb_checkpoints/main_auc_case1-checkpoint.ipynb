{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e204acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:01<00:00,  1.81s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:05<00:00,  1.85s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:19<00:00,  2.00s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:02<00:00,  1.82s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:59<00:00,  1.80s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:05<00:00,  1.86s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:11<00:00,  1.91s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:12<00:00,  1.92s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:27<00:00,  1.47s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:16<00:00,  1.36s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:19<00:00,  1.39s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:17<00:00,  1.38s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:18<00:00,  1.38s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:21<00:00,  1.41s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:18<00:00,  1.39s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:58<00:00,  1.79s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:35<00:00,  1.56s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:44<00:00,  1.64s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:31<00:00,  1.52s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:52<00:00,  1.73s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:35<00:00,  1.56s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:22<00:00,  1.42s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:30<00:00,  1.51s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:21<00:00,  1.41s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:24<00:00,  1.44s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:21<00:00,  1.41s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:26<00:00,  1.46s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:41<00:00,  1.62s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:47<00:00,  1.67s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:23<00:00,  1.44s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:35<00:00,  1.55s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:17<00:00,  1.37s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:20<00:00,  1.40s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:19<00:00,  1.39s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:24<00:00,  1.45s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:28<00:00,  1.49s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:27<00:00,  1.47s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:25<00:00,  1.45s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:29<00:00,  1.50s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:37<00:00,  1.58s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:08<00:00,  1.88s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:02<00:00,  1.82s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:50<00:00,  1.71s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:01<00:00,  1.81s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:27<00:00,  2.08s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:02<00:00,  1.83s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:07<00:00,  1.88s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:46<00:00,  1.66s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:05<00:00,  1.85s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:50<00:00,  1.71s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:55<00:00,  1.75s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:22<00:00,  1.43s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:26<00:00,  1.46s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:44<00:00,  1.64s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:55<00:00,  1.75s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:15<00:00,  1.95s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:15<00:00,  1.95s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:16<00:00,  1.97s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:18<00:00,  1.98s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:07<00:00,  1.88s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:08<00:00,  1.89s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:03<00:00,  1.84s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:29<00:00,  2.10s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:52<00:00,  2.33s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:43<00:00,  2.23s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:48<00:00,  2.29s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:20<00:00,  1.40s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:16<00:00,  1.36s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:15<00:00,  1.96s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:10<00:00,  1.90s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:52<00:00,  1.73s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:17<00:00,  1.98s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:19<00:00,  1.99s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:18<00:00,  1.98s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:31<00:00,  1.51s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:16<00:00,  1.96s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [04:15<00:00,  2.55s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [05:28<00:00,  3.28s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [09:38<00:00,  5.79s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [05:43<00:00,  3.43s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [04:40<00:00,  2.80s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:19<00:00,  1.99s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:15<00:00,  1.96s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:13<00:00,  1.93s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:12<00:00,  1.92s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:58<00:00,  2.39s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:35<00:00,  2.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:16<00:00,  1.97s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:13<00:00,  1.93s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [03:10<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# %%\n",
    "permute = True # Set permute to True to build the model from one instance of shuffled labels\n",
    "\n",
    "n_iter = 90 # Set number of iterations for permutation (1 - 100)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Loading required libraries\n",
    "from joblib import Parallel, delayed\n",
    "from dependency.progress import tqdm_joblib\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "random_seed = 208\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Load all engine feature data\n",
    "dfs = [] # List to store data frames\n",
    "\n",
    "for i in range(1, 11):\n",
    "    filename = f'engine_data/eng{i}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate dataframes\n",
    "df_d = pd.concat(dfs, ignore_index=True).fillna(0.1)\n",
    "\n",
    "# Drop features VIF >> 5\n",
    "df_d = df_d[df_d.columns.drop(['L_-b/2a True Airspeed (knots)','L_-b/2a CHT 3 (deg C)',\n",
    "                               'D_-b/2a Oil Pressure (PSI)','L_-b/2a CHT 6 (deg C)',\n",
    "                              'C_-b/2a Barometer Setting (inHg)','TO_-b/2a Barometer Setting (inHg)',\n",
    "                               'L_-b/2a Barometer Setting (inHg)','D_-b/2a Barometer Setting (inHg)'])]\n",
    "\n",
    "\n",
    "# Creating table to populate results\n",
    "Case_1_3_lgbm_fi_casc = pd.DataFrame({'Case': [],'Model': [], 'FS_Type': [],'AUC_ROC': []})\n",
    "\n",
    "# -----------------------------------------\n",
    "#Separate data classes into 3\n",
    "Xy = df_d\n",
    "\n",
    "for rand in range(90):\n",
    "\n",
    "    #Class 0 and 2\n",
    "    Xy02 = Xy[Xy.Fault != 1]\n",
    "    Xy02['Fault'].replace({2: 1}, inplace = True)\n",
    "    y02 = Xy02['Fault']\n",
    "    X02 = Xy02.drop('Fault', axis=1)\n",
    "\n",
    "    if permute == True:   \n",
    "        y02 = Xy02['Fault'].values\n",
    "        np.random.shuffle(y02)\n",
    "        Xy02['Fault'] = y02\n",
    "\n",
    "    # # -----------------------------------------\n",
    "    # # #Class 0\n",
    "    Xy0 = Xy02[Xy02.Fault == 0]\n",
    "    y0 = Xy02['Fault']\n",
    "    X0 = Xy02.drop('Fault', axis=1)\n",
    "\n",
    "    # # # -----------------------------------------\n",
    "    # # #Class 2\n",
    "    Xy2 = Xy02[Xy02.Fault == 2]\n",
    "    y2 = Xy02['Fault']\n",
    "    X2 = Xy02.drop('Fault', axis=1)\n",
    "\n",
    "    # # -----------------------------------------\n",
    "    # # Split Class 0 into 5 folds:\n",
    "    # Fold 1\n",
    "    X_train, X_test_1, y_train, y_test_1 = train_test_split(X0, y0, test_size=0.2, random_state=random_seed)\n",
    "    cv_0_0 = pd.concat([X_test_1,y_test_1], axis=1)\n",
    "\n",
    "    # Fold 2\n",
    "    X_train, X_test_2, y_train, y_test_2 = train_test_split(X_train,y_train, test_size=0.25, random_state=random_seed)\n",
    "    cv_0_1 = pd.concat([X_test_2,y_test_2], axis=1) \n",
    "\n",
    "    # Fold 3\n",
    "    X_train, X_test_3, y_train, y_test_3 = train_test_split(X_train,y_train, test_size=0.33, random_state=random_seed)\n",
    "    cv_0_2 = pd.concat([X_test_3,y_test_3], axis=1) \n",
    "\n",
    "    # Fold 4 and 5\n",
    "    X_train, X_test_4, y_train, y_test_4 = train_test_split(X_train,y_train, test_size=0.50, random_state=random_seed)\n",
    "    cv_0_3 = pd.concat([X_test_4,y_test_4], axis=1) \n",
    "    cv_0_4 = pd.concat([X_train,y_train], axis=1) \n",
    "\n",
    "    # # -----------------------------------------\n",
    "    # # Split Class 1 into 5 folds:\n",
    "    # # Fold 1\n",
    "    # X_train, X_test_1, y_train, y_test_1 = train_test_split(X1, y1, test_size=0.2, random_state=random_seed)\n",
    "    # cv_1_0 = pd.concat([X_test_1,y_test_1], axis=1)\n",
    "\n",
    "    # # Fold 2\n",
    "    # X_train, X_test_2, y_train, y_test_2 = train_test_split(X_train,y_train, test_size=0.25, random_state=random_seed)\n",
    "    # cv_1_1 = pd.concat([X_test_2,y_test_2], axis=1) \n",
    "\n",
    "    # # Fold 3\n",
    "    # X_train, X_test_3, y_train, y_test_3 = train_test_split(X_train,y_train, test_size=0.33, random_state=random_seed)\n",
    "    # cv_1_2 = pd.concat([X_test_3,y_test_3], axis=1) \n",
    "\n",
    "    # # Fold 4 and 5\n",
    "    # X_train, X_test_4, y_train, y_test_4 = train_test_split(X_train,y_train, test_size=0.50, random_state=random_seed)\n",
    "    # cv_1_3 = pd.concat([X_test_4,y_test_4], axis=1) \n",
    "    # cv_1_4 = pd.concat([X_train,y_train], axis=1) \n",
    "\n",
    "    # # -----------------------------------------\n",
    "    # # Split Class 2 into 5 folds:\n",
    "    # # Fold 1\n",
    "    X_train, X_test_1, y_train, y_test_1 = train_test_split(X2, y2, test_size=0.2, random_state=random_seed)\n",
    "    cv_2_0 = pd.concat([X_test_1,y_test_1], axis=1)\n",
    "\n",
    "    # Fold 2\n",
    "    X_train, X_test_2, y_train, y_test_2 = train_test_split(X_train,y_train, test_size=0.25, random_state=random_seed)\n",
    "    cv_2_1 = pd.concat([X_test_2,y_test_2], axis=1) \n",
    "\n",
    "    # Fold 3\n",
    "    X_train, X_test_3, y_train, y_test_3 = train_test_split(X_train,y_train, test_size=0.33, random_state=random_seed)\n",
    "    cv_2_2 = pd.concat([X_test_3,y_test_3], axis=1) \n",
    "\n",
    "    # Fold 4 and 5\n",
    "    X_train, X_test_4, y_train, y_test_4 = train_test_split(X_train,y_train, test_size=0.50, random_state=random_seed)\n",
    "    cv_2_3 = pd.concat([X_test_4,y_test_4], axis=1) \n",
    "    cv_2_4 = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "    # Set up training folds using classes 0 and 2\n",
    "    cv_0 = pd.concat([cv_0_0, cv_2_0], axis = 0)\n",
    "    cv_1 = pd.concat([cv_0_1, cv_2_1], axis = 0)\n",
    "    cv_2 = pd.concat([cv_0_2, cv_2_2], axis = 0)\n",
    "    cv_3 = pd.concat([cv_0_3, cv_2_3], axis = 0)\n",
    "    cv_4 = pd.concat([cv_0_4, cv_2_4], axis = 0)\n",
    "\n",
    "    k_fold_train_0 = pd.concat([cv_0, cv_1, cv_2, cv_3], axis = 0) #skip 4\n",
    "    ky0_train = k_fold_train_0['Fault']\n",
    "    kX0_train = k_fold_train_0.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_train_1 = pd.concat([cv_0, cv_1, cv_2, cv_4], axis = 0) #skip 3\n",
    "    ky1_train = k_fold_train_1['Fault']\n",
    "    kX1_train = k_fold_train_1.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_train_2 = pd.concat([cv_0, cv_1, cv_3, cv_4], axis = 0) #skip 2\n",
    "    ky2_train = k_fold_train_2['Fault']\n",
    "    kX2_train = k_fold_train_2.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_train_3 = pd.concat([cv_0, cv_2, cv_3, cv_4], axis = 0) #skip 1\n",
    "    ky3_train = k_fold_train_3['Fault']\n",
    "    kX3_train = k_fold_train_3.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_train_4 = pd.concat([cv_1, cv_2, cv_3, cv_4], axis = 0) #skip 0\n",
    "    ky4_train = k_fold_train_4['Fault']\n",
    "    kX4_train = k_fold_train_4.drop('Fault', axis=1)\n",
    "\n",
    "    # Set up validation folds using classes 0 and 1 \n",
    "    k_fold_val_0 = cv_4 #include 4\n",
    "    ky0_val = k_fold_val_0['Fault']\n",
    "    kX0_val = k_fold_val_0.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_val_1 = cv_3 #include 3\n",
    "    ky1_val = k_fold_val_1['Fault']\n",
    "    kX1_val = k_fold_val_1.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_val_2 = cv_2 #include 2\n",
    "    ky2_val = k_fold_val_2['Fault']\n",
    "    kX2_val = k_fold_val_2.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_val_3 = cv_1 #include 1\n",
    "    ky3_val = k_fold_val_3['Fault']\n",
    "    kX3_val = k_fold_val_3.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_val_4 = cv_0 #include 0\n",
    "    ky4_val = k_fold_val_4['Fault']\n",
    "    kX4_val = k_fold_val_4.drop('Fault', axis=1)\n",
    "\n",
    "\n",
    "    # Feature Importance for Case 1\n",
    "    y3 = Xy02['Fault']\n",
    "    X3 = Xy02.drop('Fault', axis=1)\n",
    "   \n",
    "    # Initialise LGBM Classifier        \n",
    "    lgbm = LGBMClassifier(random_state=random_seed, n_jobs=-1, force_col_wise=True, verbose=-1)\n",
    "    \n",
    "    # Undertake Feature Importance\n",
    "    lgbm.fit(X3,y3)\n",
    "    importance_1 = lgbm.feature_importances_\n",
    "\n",
    "    # Get the scores with the highest importance and make into a list\n",
    "    df_fi_1 = {\n",
    "        'Feature': range(len(importance_1)),\n",
    "        'Score': importance_1\n",
    "    }\n",
    "    df_fi_1 = pd.DataFrame(df_fi_1)\n",
    "    idx_1 = df_fi_1.sort_values('Score', ascending=False) #Feature Importance\n",
    "    aa_1 = idx_1['Feature'].to_list()\n",
    "\n",
    "    Feature_Lenght_1= len(aa_1) +1\n",
    "    result_1 = []\n",
    "    cols_1 = []\n",
    "    for i in range(Feature_Lenght_1):\n",
    "        cols_1 = aa_1[0:i]\n",
    "        result_1.append(cols_1)\n",
    "    result_1_lgbm = result_1[1:]\n",
    "\n",
    "    if len(result_1_lgbm) < 100:\n",
    "        num_features = len(result_1_lgbm)\n",
    "\n",
    "    else:\n",
    "        num_features = 100\n",
    "\n",
    "\n",
    "    ## Case 3: (0 vs 1s2) Scenario (a): Iteration\n",
    "\n",
    "    def Case_1_lgbm_nr(i):\n",
    "\n",
    "        idx_3 = result_1_lgbm[i] #fi_thresh_iterest\n",
    "        kX0_traini = kX0_train.iloc[:, idx_3] #fi_thresh_iterest\n",
    "        kX1_traini = kX1_train.iloc[:, idx_3] #fi_thresh_iterest\n",
    "        kX2_traini = kX2_train.iloc[:, idx_3] #fi_thresh_iterest\n",
    "        kX3_traini = kX3_train.iloc[:, idx_3] #fi_thresh_iterest\n",
    "        kX4_traini = kX4_train.iloc[:, idx_3] #fi_thresh_iterest\n",
    "\n",
    "        kX0_vali = kX0_val.iloc[:, idx_3] #fi_thresh_iterest\n",
    "        kX1_vali = kX1_val.iloc[:, idx_3] #fi_thresh_iterest\n",
    "        kX2_vali = kX2_val.iloc[:, idx_3] #fi_thresh_iterest\n",
    "        kX3_vali = kX3_val.iloc[:, idx_3] #fi_thresh_iterest\n",
    "        kX4_vali = kX4_val.iloc[:, idx_3] #fi_thresh_iterest\n",
    "\n",
    "\n",
    "        outSeries = pd.Series()\n",
    "        outSeries['Case'] = '1'\n",
    "        outSeries['Class'] = '0 and 2'\n",
    "        outSeries['Model'] = 'lgbm'\n",
    "        outSeries['FS_Type'] = 'lgbm_fi_casc'\n",
    "\n",
    "        lgbm.fit(kX0_traini,ky0_train)\n",
    "\n",
    "        # Prediction Probabilities\n",
    "        lgbm_probs = lgbm.predict_proba(kX0_vali)\n",
    "\n",
    "        #keep probabilities for the positive outcome only (1)\n",
    "        lgbm_probs = lgbm_probs[:,1]\n",
    "\n",
    "        # Calculate AUC_ROC\n",
    "        lgbm_auc_0 = roc_auc_score(ky0_val, lgbm_probs)\n",
    "\n",
    "        lgbm.fit(kX1_traini,ky1_train)\n",
    "        lgbm_probs = lgbm.predict_proba(kX1_vali)\n",
    "        lgbm_probs = lgbm_probs[:,1]\n",
    "        lgbm_auc_1 = roc_auc_score(ky1_val, lgbm_probs)    \n",
    "\n",
    "        lgbm.fit(kX2_traini,ky2_train)\n",
    "        lgbm_probs = lgbm.predict_proba(kX2_vali)\n",
    "        lgbm_probs = lgbm_probs[:,1]\n",
    "        lgbm_auc_2 = roc_auc_score(ky2_val, lgbm_probs)  \n",
    "\n",
    "        lgbm.fit(kX3_traini,ky3_train)\n",
    "        lgbm_probs = lgbm.predict_proba(kX3_vali)\n",
    "        lgbm_probs = lgbm_probs[:,1]\n",
    "        lgbm_auc_3 = roc_auc_score(ky3_val, lgbm_probs)\n",
    "\n",
    "        lgbm.fit(kX4_traini,ky4_train)\n",
    "        lgbm_probs = lgbm.predict_proba(kX4_vali)\n",
    "        lgbm_probs = lgbm_probs[:,1]\n",
    "        lgbm_auc_4 = roc_auc_score(ky4_val, lgbm_probs)\n",
    "\n",
    "        a = [lgbm_auc_0, lgbm_auc_1, lgbm_auc_2, lgbm_auc_3, lgbm_auc_4]\n",
    "        outSeries['AUC_ROC'] = round(np.mean(a),3)\n",
    "\n",
    "        return outSeries\n",
    "                                     \n",
    "    with tqdm_joblib(tqdm(desc=\"Percentage Completion\", total=num_features)) as progress_bar:\n",
    "        Case_1_lgbm_fi_casc_nr = pd.DataFrame(Parallel(n_jobs=-1)(delayed(Case_1_lgbm_nr)(i) for i in range(num_features)))\n",
    "\n",
    "    # ## Case 1: (0 vs 2) Problem FD: MaxIndex\n",
    "\n",
    "    maxrowindex = Case_1_lgbm_fi_casc_nr[\"AUC_ROC\"].idxmax()\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['FS_Type']] = 'lgbm_fi_casc' # CHECK FEATURE IMPORTANCE TYPE USED\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['Case']] = '1'\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['Class']] = '0 and 2'\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['Model']] = 'lgbm'\n",
    "\n",
    "    kX0_traini = kX0_train.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX1_traini = kX1_train.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX2_traini = kX2_train.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX3_traini = kX3_train.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX4_traini = kX4_train.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "\n",
    "    kX0_vali = kX0_val.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX1_vali = kX1_val.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX2_vali = kX2_val.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX3_vali = kX3_val.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX4_vali = kX4_val.iloc[:,result_1_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "\n",
    "    lgbm.fit(kX0_traini,ky0_train)\n",
    "\n",
    "    # Prediction Probabilities\n",
    "    lgbm_probs = lgbm.predict_proba(kX0_vali)\n",
    "\n",
    "    #keep probabilities for the positive outcome only (1)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "\n",
    "    # Calculate AUC_ROC\n",
    "    lgbm_auc_0 = roc_auc_score(ky0_val, lgbm_probs)\n",
    "    lgbm_fpr0 ,lgbm_tpr0, _ = roc_curve(ky0_val, lgbm_probs, pos_label=1)\n",
    "\n",
    "\n",
    "    lgbm.fit(kX1_traini,ky1_train)\n",
    "    lgbm_probs = lgbm.predict_proba(kX1_vali)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "    lgbm_auc_1 = roc_auc_score(ky1_val, lgbm_probs)    \n",
    "    lgbm_fpr1 ,lgbm_tpr1, _ = roc_curve(ky1_val, lgbm_probs, pos_label=1)\n",
    "\n",
    "    lgbm.fit(kX2_traini,ky2_train)\n",
    "    lgbm_probs = lgbm.predict_proba(kX2_vali)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "    lgbm_auc_2 = roc_auc_score(ky2_val, lgbm_probs)  \n",
    "    lgbm_fpr2 ,lgbm_tpr2, _ = roc_curve(ky2_val, lgbm_probs, pos_label=1)\n",
    "\n",
    "\n",
    "    lgbm.fit(kX3_traini,ky3_train)\n",
    "    lgbm_probs = lgbm.predict_proba(kX3_vali)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "    lgbm_auc_3 = roc_auc_score(ky3_val, lgbm_probs)\n",
    "    lgbm_fpr3 ,lgbm_tpr3, _ = roc_curve(ky3_val, lgbm_probs, pos_label=1)\n",
    "\n",
    "\n",
    "    lgbm.fit(kX4_traini,ky4_train)\n",
    "    lgbm_probs = lgbm.predict_proba(kX4_vali)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "    lgbm_auc_4 = roc_auc_score(ky4_val, lgbm_probs)\n",
    "    lgbm_fpr4 ,lgbm_tpr4, _ = roc_curve(ky4_val, lgbm_probs, pos_label=1)\n",
    "\n",
    "    a = [lgbm_auc_0, lgbm_auc_1, lgbm_auc_2, lgbm_auc_3, lgbm_auc_4]\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['AUC_ROC']] = [str(\"%.3f\" % np.mean(a))]\n",
    "\n",
    "\n",
    "    tpr = [lgbm_tpr0, lgbm_tpr1, lgbm_tpr2, lgbm_tpr3, lgbm_tpr4]\n",
    "    fpr = [lgbm_fpr0, lgbm_fpr1, lgbm_fpr2, lgbm_fpr3, lgbm_fpr4]\n",
    "\n",
    "\n",
    "    Case_1_3_lgbm_fi_casc.to_csv(f'rand_auc_case1/new_lgbm_fi_casc_Case_1_misclass_rand_{str(rand)}.csv', index=False)\n",
    "\n",
    "    # Save True and False Positive Rates for AUC Plot\n",
    "    df_fpr, df_tpr = pd.DataFrame(fpr), pd.DataFrame(tpr)\n",
    "    df_fpr_T, df_tpr_T  =  df_fpr.T, df_tpr.T\n",
    "    df_fpr_T.columns, df_tpr_T.columns  =['fpr_0','fpr_1','fpr_2','fpr_3','fpr_4'], ['tpr_0','tpr_1','tpr_2','tpr_3','tpr_4']\n",
    "    df = pd.concat([df_fpr_T, df_tpr_T], axis=1)\n",
    "    df.to_csv(f'rand_ftpr_case1/new_lgbm_fi_casc_ftpr_Case_1_nr_misclass_rand_{str(rand)}.csv', index=False)\n",
    "# %%\n",
    "# 0.956, 0.752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967a182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
