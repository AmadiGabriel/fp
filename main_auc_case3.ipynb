{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e204acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:04<00:00,  1.25s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:09<00:00,  1.30s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:57<00:00,  1.18s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:56<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:56<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:57<00:00,  1.18s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:05<00:00,  1.26s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:56<00:00,  1.17s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:06<00:00,  1.27s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:56<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.14s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:52<00:00,  1.13s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:05<00:00,  1.25s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:53<00:00,  1.14s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:59<00:00,  1.19s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:56<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:53<00:00,  1.14s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:59<00:00,  1.20s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:56<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:05<00:00,  1.25s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:53<00:00,  1.13s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.14s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:56<00:00,  1.17s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:55<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:58<00:00,  1.19s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:56<00:00,  1.16s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:59<00:00,  1.20s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:46<00:00,  1.06s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.04s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:45<00:00,  1.05s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:44<00:00,  1.04s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:45<00:00,  1.05s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:41<00:00,  1.02s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:44<00:00,  1.05s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:45<00:00,  1.05s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:57<00:00,  1.18s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:57<00:00,  1.17s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:03<00:00,  1.24s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [02:09<00:00,  1.29s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:57<00:00,  1.18s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:57<00:00,  1.18s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:53<00:00,  1.14s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.04s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:54<00:00,  1.15s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:45<00:00,  1.06s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.02s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:41<00:00,  1.02s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:48<00:00,  1.09s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.04s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:44<00:00,  1.05s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.04s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.04s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:48<00:00,  1.08s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.02s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:41<00:00,  1.02s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:40<00:00,  1.01s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:41<00:00,  1.02s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:47<00:00,  1.07s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:41<00:00,  1.02s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:44<00:00,  1.04s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:46<00:00,  1.06s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/it]\n",
      "Percentage Completion: 100%|█████████████████████████████████████████████████████████| 100/100 [01:43<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# %%\n",
    "permute = True # Set permute to True to build the model from one instance of shuffled labels\n",
    "\n",
    "n_iter = 90 # Set number of iterations for permutation (1 - 100)\n",
    "\n",
    "# # -----------------------------------------\n",
    "# Loading required libraries\n",
    "from joblib import Parallel, delayed\n",
    "from dependency.progress import tqdm_joblib\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "random_seed = 1\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Load all engine feature data\n",
    "dfs = [] # List to store data frames\n",
    "\n",
    "for i in range(1, 11):\n",
    "    filename = f'engine_data/eng{i}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate dataframes\n",
    "df_d = pd.concat(dfs, ignore_index=True).fillna(0.1)\n",
    "\n",
    "# Drop features VIF >> 5\n",
    "df_d = df_d[df_d.columns.drop(['L_-b/2a True Airspeed (knots)','L_-b/2a CHT 3 (deg C)',\n",
    "                               'D_-b/2a Oil Pressure (PSI)','L_-b/2a CHT 6 (deg C)',\n",
    "                              'C_-b/2a Barometer Setting (inHg)','TO_-b/2a Barometer Setting (inHg)',\n",
    "                               'L_-b/2a Barometer Setting (inHg)','D_-b/2a Barometer Setting (inHg)'])]\n",
    "\n",
    "# Creating table to populate results\n",
    "Case_1_3_lgbm_fi_casc = pd.DataFrame({'Case': [],'Model': [], 'FS_Type': [],'AUC_ROC': []})\n",
    "\n",
    "for rand in range(n_iter):  \n",
    "\n",
    "    # -----------------------------------------\n",
    "    Xy = df_d.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "    if permute == True:   \n",
    "        y = Xy['Fault'].values\n",
    "        np.random.seed(rand) \n",
    "        np.random.shuffle(y)\n",
    "        Xy['Fault'] = y\n",
    "\n",
    "    #Separate data classes into 3\n",
    "    # -----------------------------------------\n",
    "    #Class 0\n",
    "    Xy0 = Xy[Xy.Fault == 0]\n",
    "    X0, y0 = Xy0.drop('Fault', axis=1), Xy0['Fault']\n",
    "\n",
    "    #Class 1\n",
    "    Xy1 = Xy[Xy.Fault == 1]\n",
    "    X1, y1 = Xy1.drop('Fault', axis=1), Xy1['Fault']\n",
    "\n",
    "    #Class 2\n",
    "    Xy2 = Xy[Xy.Fault == 2]\n",
    "    X2, y2 = Xy2.drop('Fault', axis=1), Xy2['Fault']\n",
    "    # -----------------------------------------\n",
    "\n",
    "    # Calculate the indices for splitting into 5 equal parts\n",
    "    indices0, indices1, indices2  = (np.linspace(0, len(Xy0), num=6, dtype=int), \n",
    "                                     np.linspace(0, len(Xy1), num=6, dtype=int),\n",
    "                                     np.linspace(0, len(Xy2), num=6, dtype=int))\n",
    "\n",
    "    # -----------------------------------------\n",
    "    ## Split Classes into 5 folds\n",
    "    split_dfs0 = [Xy0.iloc[indices0[i]:indices0[i+1]] for i in range(len(indices0)-1)]\n",
    "    cv_0_0, cv_0_1, cv_0_2, cv_0_3, cv_0_4 = split_dfs0\n",
    "\n",
    "    split_dfs1 = [Xy1.iloc[indices1[i]:indices1[i+1]] for i in range(len(indices1)-1)]\n",
    "    cv_1_0, cv_1_1, cv_1_2, cv_1_3, cv_1_4 = split_dfs1\n",
    "\n",
    "    split_dfs2 = [Xy2.iloc[indices2[i]:indices2[i+1]] for i in range(len(indices2)-1)]\n",
    "    cv_2_0, cv_2_1, cv_2_2, cv_2_3, cv_2_4 = split_dfs2\n",
    "    # Set up training folds using classes 0, 1 and 2; shuffle rows and reset indexes\n",
    "    tr_cv_0 = pd.concat([cv_0_0, cv_1_0, cv_2_0], axis = 0)\n",
    "    tr_cv_1 = pd.concat([cv_0_1, cv_1_1, cv_2_1], axis = 0)\n",
    "    tr_cv_2 = pd.concat([cv_0_2, cv_1_2, cv_2_2], axis = 0)\n",
    "    tr_cv_3 = pd.concat([cv_0_3, cv_1_3, cv_2_3], axis = 0)\n",
    "    tr_cv_4 = pd.concat([cv_0_4, cv_1_4, cv_2_4], axis = 0)\n",
    "\n",
    "    k_fold_train_0 = pd.concat([tr_cv_0, tr_cv_1, tr_cv_2, tr_cv_3], axis = 0) #skip 4\n",
    "    ky0_train = k_fold_train_0['Fault'].replace({2: 1})\n",
    "    kX0_train = k_fold_train_0.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_train_1 = pd.concat([tr_cv_0, tr_cv_1, tr_cv_2, tr_cv_4], axis = 0) #skip 3\n",
    "    ky1_train = k_fold_train_1['Fault'].replace({2: 1})\n",
    "    kX1_train = k_fold_train_1.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_train_2 = pd.concat([tr_cv_0, tr_cv_1, tr_cv_3, tr_cv_4], axis = 0) #skip 2\n",
    "    ky2_train = k_fold_train_2['Fault'].replace({2: 1})\n",
    "    kX2_train = k_fold_train_2.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_train_3 = pd.concat([tr_cv_0, tr_cv_2, tr_cv_3, tr_cv_4], axis = 0) #skip 1\n",
    "    ky3_train = k_fold_train_3['Fault'].replace({2: 1})\n",
    "    kX3_train = k_fold_train_3.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_train_4 = pd.concat([tr_cv_1, tr_cv_2, tr_cv_3, tr_cv_4], axis = 0) #skip 0\n",
    "    ky4_train = k_fold_train_4['Fault'].replace({2: 1})\n",
    "    kX4_train = k_fold_train_4.drop('Fault', axis=1)\n",
    "\n",
    "    # Set up test folds using classes 0 and 1; shuffle rows and reset indexes\n",
    "    te_cv_0 = pd.concat([cv_0_0, cv_1_0], axis = 0)\n",
    "    te_cv_1 = pd.concat([cv_0_1, cv_1_1], axis = 0)\n",
    "    te_cv_2 = pd.concat([cv_0_2, cv_1_2], axis = 0)\n",
    "    te_cv_3 = pd.concat([cv_0_3, cv_1_3], axis = 0)\n",
    "    te_cv_4 = pd.concat([cv_0_4, cv_1_4], axis = 0)\n",
    "\n",
    "    k_fold_test_0 = te_cv_4 #include 4\n",
    "    ky0_test = k_fold_test_0['Fault']\n",
    "    kX0_test = k_fold_test_0.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_test_1 = te_cv_3 #include 3\n",
    "    ky1_test = k_fold_test_1['Fault']\n",
    "    kX1_test = k_fold_test_1.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_test_2 = te_cv_2 #include 2\n",
    "    ky2_test = k_fold_test_2['Fault']\n",
    "    kX2_test = k_fold_test_2.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_test_3 = te_cv_1 #include 1\n",
    "    ky3_test = k_fold_test_3['Fault']\n",
    "    kX3_test = k_fold_test_3.drop('Fault', axis=1)\n",
    "\n",
    "    k_fold_test_4 = te_cv_0 #include 0\n",
    "    ky4_test = k_fold_test_4['Fault']\n",
    "    kX4_test = k_fold_test_4.drop('Fault', axis=1)\n",
    "\n",
    "    X3, y3 = Xy.drop('Fault', axis=1), Xy['Fault'].replace({2: 1}) \n",
    "\n",
    "    # Initialise LGBM Classifier        \n",
    "    lgbm = LGBMClassifier(random_state=random_seed, n_jobs=-1, verbose=-1)\n",
    "    # Undertake Feature Importance\n",
    "    lgbm.fit(X3,y3)\n",
    "    importance_1 = lgbm.feature_importances_\n",
    "    \n",
    "    # Get the scores with the highest importance and make into a list\n",
    "    df_fi_1 = {\n",
    "        'Feature': range(len(importance_1)),\n",
    "        'Score': importance_1\n",
    "    }\n",
    "    df_fi_1 = pd.DataFrame(df_fi_1)\n",
    "    idx_1 = df_fi_1.sort_values('Score', ascending=False) #Feature Importance\n",
    "\n",
    "    aa_1 = idx_1['Feature'].to_list()\n",
    "\n",
    "    Feature_Lenght_1= len(aa_1) +1\n",
    "    result_1 = []\n",
    "    cols_1 = []\n",
    "\n",
    "    # # Build feature array\n",
    "    for i in range(Feature_Lenght_1):\n",
    "        cols_1 = aa_1[0:i]\n",
    "        result_1.append(cols_1)\n",
    "    result_3_lgbm = result_1[1:]\n",
    "\n",
    "    if len(result_3_lgbm) < 100:\n",
    "        num_features = len(result_3_lgbm)\n",
    "    else:\n",
    "        num_features = 100\n",
    "\n",
    "    # Feature selection based on feature array\n",
    "    def Problem_FPs_lgbm(i):\n",
    "        idx_3 = result_3_lgbm[i] \n",
    "        kX0_traini, kX0_testi = kX0_train.iloc[:, idx_3], kX0_test.iloc[:, idx_3] \n",
    "        kX1_traini, kX1_testi = kX1_train.iloc[:, idx_3], kX1_test.iloc[:, idx_3] \n",
    "        kX2_traini, kX2_testi = kX2_train.iloc[:, idx_3], kX2_test.iloc[:, idx_3]  \n",
    "        kX3_traini, kX3_testi = kX3_train.iloc[:, idx_3], kX3_test.iloc[:, idx_3]  \n",
    "        kX4_traini, kX4_testi = kX4_train.iloc[:, idx_3], kX4_test.iloc[:, idx_3]  \n",
    "\n",
    "        outSeries = pd.Series()\n",
    "        lgbm.fit(kX0_traini,ky0_train)\n",
    "        lgbm_probs = lgbm.predict_proba(kX0_testi)[:,1]\n",
    "        lgbm_auc_0 = roc_auc_score(ky0_test, lgbm_probs)\n",
    "\n",
    "        lgbm.fit(kX1_traini,ky1_train)\n",
    "        lgbm_probs = lgbm.predict_proba(kX1_testi)[:,1]\n",
    "        lgbm_auc_1 = roc_auc_score(ky1_test, lgbm_probs)    \n",
    "\n",
    "        lgbm.fit(kX2_traini,ky2_train)\n",
    "        lgbm_probs = lgbm.predict_proba(kX2_testi)[:,1]\n",
    "        lgbm_auc_2 = roc_auc_score(ky2_test, lgbm_probs)  \n",
    "\n",
    "        lgbm.fit(kX3_traini,ky3_train)\n",
    "        lgbm_probs = lgbm.predict_proba(kX3_testi)[:,1]\n",
    "        lgbm_auc_3 = roc_auc_score(ky3_test, lgbm_probs)\n",
    "\n",
    "        lgbm.fit(kX4_traini,ky4_train)\n",
    "        lgbm_probs = lgbm.predict_proba(kX4_testi)[:,1]\n",
    "        lgbm_auc_4 = roc_auc_score(ky4_test, lgbm_probs)\n",
    "\n",
    "        # Compute mean AUC of 5 folds\n",
    "        a = [lgbm_auc_0, lgbm_auc_1, lgbm_auc_2, lgbm_auc_3, lgbm_auc_4]\n",
    "        outSeries['AUC_ROC'] = round(np.mean(a),3)\n",
    "\n",
    "        return outSeries\n",
    "    with tqdm_joblib(tqdm(desc=\"Percentage Completion\", total=num_features)) as progress_bar:\n",
    "        Case_3_lgbm = pd.DataFrame(Parallel(n_jobs=-1)(delayed(Problem_FPs_lgbm)(i) for i in range(num_features)))\n",
    "\n",
    "    maxrowindex = Case_3_lgbm[\"AUC_ROC\"].idxmax()\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['FS_Type']] = 'lgbm_fi_casc' # CHECK FEATURE IMPORTANCE TYPE USED\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['Case']] = '3'\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['Class']] = '0 and 1s2'\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['Model']] = 'lgbm'\n",
    "\n",
    "    kX0_traini = kX0_train.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX1_traini = kX1_train.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX2_traini = kX2_train.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX3_traini = kX3_train.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX4_traini = kX4_train.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "\n",
    "    kX0_testi = kX0_test.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX1_testi = kX1_test.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX2_testi = kX2_test.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX3_testi = kX3_test.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "    kX4_testi = kX4_test.iloc[:,result_3_lgbm[maxrowindex]] #fi_thresh_iterest\n",
    "\n",
    "    lgbm.fit(kX0_traini,ky0_train)\n",
    "\n",
    "    # Prediction Probabilities\n",
    "    lgbm_probs = lgbm.predict_proba(kX0_testi)\n",
    "\n",
    "    #keep probabilities for the positive outcome only (1)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "\n",
    "    # Calculate AUC_ROC\n",
    "    lgbm_auc_0 = roc_auc_score(ky0_test, lgbm_probs)\n",
    "    lgbm_fpr0 ,lgbm_tpr0, _ = roc_curve(ky0_test, lgbm_probs, pos_label=1)\n",
    "\n",
    "    lgbm.fit(kX1_traini,ky1_train)\n",
    "    lgbm_probs = lgbm.predict_proba(kX1_testi)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "    lgbm_auc_1 = roc_auc_score(ky1_test, lgbm_probs)    \n",
    "    lgbm_fpr1 ,lgbm_tpr1, _ = roc_curve(ky1_test, lgbm_probs, pos_label=1)\n",
    "\n",
    "    lgbm.fit(kX2_traini,ky2_train)\n",
    "    lgbm_probs = lgbm.predict_proba(kX2_testi)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "    lgbm_auc_2 = roc_auc_score(ky2_test, lgbm_probs)  \n",
    "    lgbm_fpr2 ,lgbm_tpr2, _ = roc_curve(ky2_test, lgbm_probs, pos_label=1)\n",
    "\n",
    "    lgbm.fit(kX3_traini,ky3_train)\n",
    "    lgbm_probs = lgbm.predict_proba(kX3_testi)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "    lgbm_auc_3 = roc_auc_score(ky3_test, lgbm_probs)\n",
    "    lgbm_fpr3 ,lgbm_tpr3, _ = roc_curve(ky3_test, lgbm_probs, pos_label=1)\n",
    "\n",
    "    lgbm.fit(kX4_traini,ky4_train)\n",
    "    lgbm_probs = lgbm.predict_proba(kX4_testi)\n",
    "    lgbm_probs = lgbm_probs[:,1]\n",
    "    lgbm_auc_4 = roc_auc_score(ky4_test, lgbm_probs)\n",
    "    lgbm_fpr4 ,lgbm_tpr4, _ = roc_curve(ky4_test, lgbm_probs, pos_label=1)\n",
    "\n",
    "    a = [lgbm_auc_0, lgbm_auc_1, lgbm_auc_2, lgbm_auc_3, lgbm_auc_4]\n",
    "    Case_1_3_lgbm_fi_casc.loc[0,['AUC_ROC']] = [str(\"%.3f\" % np.mean(a))]\n",
    "\n",
    "    tpr = [lgbm_tpr0, lgbm_tpr1, lgbm_tpr2, lgbm_tpr3, lgbm_tpr4]\n",
    "    fpr = [lgbm_fpr0, lgbm_fpr1, lgbm_fpr2, lgbm_fpr3, lgbm_fpr4]\n",
    "\n",
    "    Case_1_3_lgbm_fi_casc.to_csv(f'rand_auc_case3/new_lgbm_fi_casc_Case_3_misclass_rand_{str(rand)}.csv', index=False)\n",
    "\n",
    "    # Save True and False Positive Rates for AUC Plot\n",
    "    df_fpr, df_tpr = pd.DataFrame(fpr), pd.DataFrame(tpr)\n",
    "    df_fpr_T, df_tpr_T  =  df_fpr.T, df_tpr.T\n",
    "    df_fpr_T.columns, df_tpr_T.columns  =['fpr_0','fpr_1','fpr_2','fpr_3','fpr_4'], ['tpr_0','tpr_1','tpr_2','tpr_3','tpr_4']\n",
    "    df = pd.concat([df_fpr_T, df_tpr_T], axis=1)\n",
    "    df.to_csv(f'rand_ftpr_case3/new_lgbm_fi_casc_ftpr_Case_3_nr_misclass_rand_{str(rand)}.csv', index=False)\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a79fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
